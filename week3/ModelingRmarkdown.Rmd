---
title: "Trips Modeling"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setting up the training set, validate, and test set
This section is to load in libraries and the trips_per_day data set. We separate them into a training set, a validate set, and a test set with proportions 0.9, 0.1, and 0.1.

```{r clean data}

library(tidyverse)
library(scales)
library(modelr)
library(lubridate)

theme_set(theme_bw())
options(repr.plot.width=4, repr.plot.height=3)

trips_per_day <- read_tsv('trips_per_day.tsv')
head(trips_per_day)
holidays <- read.delim2('holidays',header=F,sep = ',',
                        col.names = c('i','ymd','holiday'),
                        colClasses = c("integer","Date","character")) %>% select(ymd,holiday)
holidays <- holidays %>% filter(ymd >= "2014-01-01" & ymd < "2015-01-01")

trips_per_day <- trips_per_day %>% left_join(holidays,by='ymd')

trips_per_day <- trips_per_day %>% mutate(if_holiday = if_else(is.na(holiday),0,1)) %>%
  mutate(week_day = if_else(wday(ymd)>1 & wday(ymd)<7,1,0)) %>%
  mutate(rain = if_else(prcp>0.5,1,0)) %>%
  mutate(deep_snow = if_else(snwd>=0.5, snwd, 0))

frac_train = 0.8
frac_test = 0.1

set.seed(38)

num_days <- nrow(trips_per_day)
frac_train <- 0.8
num_train <- floor(num_days * frac_train)

# randomly sample rows for the training set 
train <- sample(1:num_days, num_train, replace=F)

# training set used to fit the model
trips_per_day_train <- trips_per_day[train, ]

# validate and test sets used to evaluate the fit
test_validate_set <- trips_per_day[-train, ]
num_test_validate <- floor((num_days - num_train)/2)
validate <- sample(nrow(test_validate_set),num_test_validate,replace = F)
trips_per_day_validate <- test_validate_set[validate,]
trips_per_day_test <- test_validate_set[-validate,]


```

## Trips Models of features minimum temperature and snow

Compare between different polynomial power of minimum temperature and then plot the results by RMSE of training and validating.
```{r cars}
K <- 1:8
train_err <- c()
validate_err <- c()
for (k in K) {
  
  # fit on the training data
  model <- lm(num_trips ~ poly(tmin,k,raw = T) + snwd , data = trips_per_day_train)
  
  # evaluate on the training data
  train_err[k] <- sqrt(mean((predict(model, trips_per_day_train) - trips_per_day_train$num_trips)^2))
  
  # evaluate on the validate data
  validate_err[k] <- sqrt(mean((predict(model, trips_per_day_validate) - trips_per_day_validate$num_trips)^2))
}
plot_data <- data.frame(K, train_err, validate_err) %>%
  gather("split", "error", -K)

ggplot(plot_data, aes(x=K, y=error, color=split)) +
  geom_line() +
  scale_x_continuous(breaks=K) +
  xlab('Polynomial Degree') +
  ylab('RMSE')

train_err
validate_err
```

The lowest RMSE for validating seems to be at polynomial degree 6. The corresponding values are 5374 and 5056 for training error and validating error.

## Trips Models of tmin, tmax, snwd, and holiday

Let's try experimenting with minimum temperature and maximum temperature. People are more likely to ride a bike when the temperature is not too cold or hot. We will also add in if it's snowing a lot, as well as holidays.

```{r pressure, echo=FALSE}
K <- 1:8
train_err <- c()
validate_err <- c()
for (k in K) {
  
  # fit on the training data
  model <- lm(num_trips ~ poly(tmin,k,raw = T) + poly(tmax,k,raw=T) + snwd + if_holiday, data = trips_per_day_train)
  
  # evaluate on the training data
  train_err[k] <- sqrt(mean((predict(model, trips_per_day_train) - trips_per_day_train$num_trips)^2))
  
  # evaluate on the validate data
  validate_err[k] <- sqrt(mean((predict(model, trips_per_day_validate) - trips_per_day_validate$num_trips)^2))
}
plot_data <- data.frame(K, train_err, validate_err) %>%
  gather("split", "error", -K)

ggplot(plot_data, aes(x=K, y=error, color=split)) +
  geom_line() +
  scale_x_continuous(breaks=K) +
  xlab('Polynomial Degree') +
  ylab('RMSE')

train_err
validate_err
```

To minimize complexity, we will select the polynomial degree 4 as the best model out of this assumption. The error rate is 4866 and 4786 for training and validating.

## Trips Models of tmax, snwd, and weekdays

What if riders don't care if it's too cold unless it's snowing? We will consider the features of max temperature, snowing, and if its weekdays. 

```{r}
K <- 1:8
train_err <- c()
validate_err <- c()
for (k in K) {
  
  # fit on the training data
  model <- lm(num_trips ~ poly(tmax,k,raw = T) + snwd + week_day, data = trips_per_day_train)
  
  # evaluate on the training data
  train_err[k] <- sqrt(mean((predict(model, trips_per_day_train) - trips_per_day_train$num_trips)^2))
  
  # evaluate on the validate data
  validate_err[k] <- sqrt(mean((predict(model, trips_per_day_validate) - trips_per_day_validate$num_trips)^2))
}
plot_data <- data.frame(K, train_err, validate_err) %>%
  gather("split", "error", -K)

ggplot(plot_data, aes(x=K, y=error, color=split)) +
  geom_line() +
  scale_x_continuous(breaks=K) +
  xlab('Polynomial Degree') +
  ylab('RMSE')

train_err
validate_err
```
This model seems to work better than the previous ones. The resulting RMSEs here are 4549 and 4035. We seem to be on the right track so we will try combining this with the idea that when it's raining and cold, people are less likely to use the bike.

## Trips Models of tmax, snwd, weekdays, and tmin*rain
We predetermined the weather to be heavily raining when precipitation is more than 0.5. Our model will combine the features tmin and whether it heavily rains using the * operator in the lm function. 
```{r}
K <- 1:8
train_err <- c()
validate_err <- c()
for (k in K) {
  
  # fit on the training data
  model <- lm(num_trips ~ poly(tmax,k,raw = T) + snwd + week_day + tmin*rain , data = trips_per_day_train)
  
  # evaluate on the training data
  train_err[k] <- sqrt(mean((predict(model, trips_per_day_train) - trips_per_day_train$num_trips)^2))
  
  # evaluate on the validate data
  validate_err[k] <- sqrt(mean((predict(model, trips_per_day_validate) - trips_per_day_validate$num_trips)^2))
}
plot_data <- data.frame(K, train_err, validate_err) %>%
  gather("split", "error", -K)

ggplot(plot_data, aes(x=K, y=error, color=split)) +
  geom_line() +
  scale_x_continuous(breaks=K) +
  xlab('Polynomial Degree') +
  ylab('RMSE')

train_err
validate_err

```

The results look much more promising with the best validating RMSE at polynomial degree 4 for tmax. RMSEs are: 3907 and 3137 for training and validating. We will select this as our winning model. 

